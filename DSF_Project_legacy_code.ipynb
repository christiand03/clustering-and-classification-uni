{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326bc5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize the data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(preprocessed_train_data)\n",
    "X_test_tfidf = vectorizer.transform(preprocessed_test_data)\n",
    "\n",
    "# Example usage of preprocessed and vectorized data\n",
    "print(\"Original Sample:\", newsgroups_train.data[0])\n",
    "print(\"Preprocessed Sample:\", preprocessed_train_data[0])\n",
    "print(\"TF-IDF Vectorized Shape (Training):\", X_train_tfidf.shape)\n",
    "print(\"TF-IDF Vectorized Shape (Testing):\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660eba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Elbow method to find the optimal number of clusters\n",
    "inertia = []\n",
    "cluster_range = range(1, 26)  # Test for 1 to 25 clusters\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_train_tfidf)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(cluster_range, inertia, marker='o')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Silhouette score to find the optimal number of clusters\n",
    "silhouette_scores = []\n",
    "cluster_range = range(10, 26)  # Test for 10 to 25 clusters\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_train_tfidf)\n",
    "    score = silhouette_score(X_train_tfidf, labels)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plot the silhouette scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(cluster_range, silhouette_scores, marker='o')\n",
    "plt.title('Silhouette Score for Optimal K')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()\n",
    "\n",
    "# Choose the optimal number of clusters\n",
    "optimal_clusters = cluster_range[silhouette_scores.index(max(silhouette_scores))]\n",
    "print(\"Optimal number of clusters based on silhouette score:\", optimal_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f788f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_clusters = 20\n",
    "\n",
    "# Perform k-means clustering\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42, n_init=10)\n",
    "kmeans.fit(X_train_tfidf)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Example output of clustering\n",
    "print(\"K-Means clustering performed with\", optimal_clusters, \"clusters.\")\n",
    "print(\"Cluster Labels for Training Data (first 10):\", labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675fb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim_matrix = cosine_similarity(X_train_tfidf)\n",
    "\n",
    "# Normalize similarity values to range [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "cosine_sim_matrix = scaler.fit_transform(cosine_sim_matrix)\n",
    "\n",
    "# Convert cosine similarity to distance (1 - similarity)\n",
    "cosine_distance_matrix = 1 - cosine_sim_matrix\n",
    "\n",
    "# Apply DBSCAN using the distance matrix\n",
    "dbscan = DBSCAN(metric='precomputed', eps=0.4, min_samples=5)\n",
    "labels = dbscan.fit_predict(cosine_distance_matrix)\n",
    "\n",
    "# Print cluster labels\n",
    "print(\"DBSCAN Clustering Labels:\", labels)\n",
    "\n",
    "# Count number of clusters and noise points\n",
    "num_clusters = len(set(labels)) - (1 if -1 in labels else 0)  # -1 is the noise label\n",
    "num_noise = list(labels).count(-1)\n",
    "print(\"Number of Clusters:\", num_clusters)\n",
    "print(\"Number of Noise Points:\", num_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36097be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate silhouette score (excluding noise points if present)\n",
    "if num_clusters > 1:\n",
    "    valid_indices = labels != -1  # Exclude noise points\n",
    "    silhouette_avg = silhouette_score(cosine_distance_matrix[valid_indices][:, valid_indices], labels[valid_indices], metric='precomputed')\n",
    "    print(\"Silhouette Score:\", silhouette_avg)\n",
    "else:\n",
    "    print(\"Silhouette Score cannot be calculated with less than 2 clusters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff1996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity\n",
    "cosine_sim_matrix = cosine_similarity(X_train_tfidf)\n",
    "\n",
    "# Normalize similarity values to range [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "cosine_sim_matrix = scaler.fit_transform(cosine_sim_matrix)\n",
    "\n",
    "# Convert cosine similarity to distance (1 - similarity)\n",
    "cosine_distance_matrix = 1 - cosine_sim_matrix\n",
    "\n",
    "# Explicitly zero out diagonal values\n",
    "# Check diagonal values before applying the fix\n",
    "diagonal_values_before = np.diag(cosine_distance_matrix)\n",
    "print(\"Diagonal Values Before Fix:\", diagonal_values_before)\n",
    "\n",
    "# Check if the entire diagonal is exactly zero\n",
    "if np.all(np.diag(cosine_distance_matrix) == 0):\n",
    "    print(\"The diagonal is exactly set to zero.\")\n",
    "else:\n",
    "    print(\"There are non-zero values in the diagonal.\")\n",
    "\n",
    "# Ensure diagonal values are exactly zero\n",
    "np.fill_diagonal(cosine_distance_matrix, 0)\n",
    "\n",
    "# Check diagonal values after applying the fix\n",
    "diagonal_values_after = np.diag(cosine_distance_matrix)\n",
    "print(\"Diagonal Values After Fix:\", diagonal_values_after)\n",
    "\n",
    "# Check if the entire diagonal is exactly zero\n",
    "if np.all(np.diag(cosine_distance_matrix) == 0):\n",
    "    print(\"The diagonal is exactly set to zero.\")\n",
    "else:\n",
    "    print(\"There are non-zero values in the diagonal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import HDBSCAN\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim_matrix = cosine_similarity(X_train_tfidf)\n",
    "\n",
    "# Normalize similarity values to range [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "cosine_sim_matrix = scaler.fit_transform(cosine_sim_matrix)\n",
    "\n",
    "\n",
    "# Convert cosine similarity to distance (1 - similarity)\n",
    "cosine_distance_matrix = 1 - cosine_sim_matrix\n",
    "\n",
    "\n",
    "# Apply HDBSCAN using cosine similarity\n",
    "hdbscan_clusterer = HDBSCAN(metric='precomputed', min_cluster_size=5, min_samples=5)\n",
    "labels = hdbscan_clusterer.fit_predict(cosine_distance_matrix)\n",
    "\n",
    "# Print cluster labels\n",
    "print(\"HDBSCAN Clustering Labels:\", labels)\n",
    "\n",
    "# Count number of clusters and noise points\n",
    "num_clusters = len(set(labels)) - (1 if -1 in labels else 0)  # -1 is the noise label\n",
    "num_noise = list(labels).count(-1)\n",
    "print(\"Number of Clusters:\", num_clusters)\n",
    "print(\"Number of Noise Points:\", num_noise)\n",
    "\n",
    "# Ensure diagonal values are exactly zero\n",
    "np.fill_diagonal(cosine_distance_matrix, 0)\n",
    "\n",
    "# Check if the entire diagonal is exactly zero\n",
    "if np.all(np.diag(cosine_distance_matrix) == 0):\n",
    "    print(\"The diagonal is exactly set to zero.\")\n",
    "else:\n",
    "    print(\"There are non-zero values in the diagonal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim_matrix = cosine_similarity(X_train_tfidf)\n",
    "\n",
    "k = 10  # Number of nearest neighbors\n",
    "cosine_similarity_matrix = kneighbors_graph(X_train_tfidf, n_neighbors=k, mode='connectivity').toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4565a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import connected_components\n",
    "\n",
    "\n",
    "# Check connected components\n",
    "n_connected_components, labels = connected_components(csgraph=cosine_similarity_matrix, directed=False)\n",
    "print(f\"Number of connected components: {n_connected_components}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
